{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Cifar10 local training  \n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note, you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ./setup.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-opennre'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    ## Set type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 's3://sagemaker-us-east-1-579019700964/data/FinRE', 'pretrain': 's3://sagemaker-us-east-1-579019700964/pretrain/tencent'}\n"
     ]
    }
   ],
   "source": [
    "data_inputs = sagemaker_session.upload_data(path='../example/benchmark/FinRE', bucket=bucket, key_prefix='data/FinRE')\n",
    "pretrain_inputs = sagemaker_session.upload_data(path='../example/pretrain/tencent', bucket=bucket, key_prefix='pretrain/tencent')\n",
    "inputs = {'training': data_inputs, 'pretrain': pretrain_inputs}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpzugroy_algo-1-9lkag_1 ... \n",
      "\u001b[1BAttaching to tmpzugroy_algo-1-9lkag_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:21:59,368 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:21:59,395 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:21:59,398 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:22:02,420 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m /opt/conda/bin/python -m pip install . -r requirements.txt\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Processing /tmp/tmpzi8x83fx/module_dir\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: wheel in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.34.2)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting nltk==3.4.5\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 15.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting boto3==1.10.46\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading boto3-1.10.46-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 40.8 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting botocore==1.13.46\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading botocore-1.13.46-py2.py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 42.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: certifi==2019.11.28 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (2019.11.28)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: chardet==3.0.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (3.0.4)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting Click==7.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: docutils==0.15.2 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (0.15.2)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: idna==2.8 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2.8)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting jmespath==0.9.4\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading jmespath-0.9.4-py2.py3-none-any.whl (24 kB)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: joblib==0.14.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.14.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting numpy==1.18.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 37.7 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (2.8.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting regex==2019.12.20\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading regex-2019.12.20-cp36-cp36m-manylinux2010_x86_64.whl (689 kB)\n",
      "\u001b[K     |████████████████████████████████| 689 kB 29.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (2.22.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting s3transfer==0.2.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading s3transfer-0.2.1-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting sacremoses==0.0.38\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading sacremoses-0.0.38.tar.gz (860 kB)\n",
      "\u001b[K     |████████████████████████████████| 860 kB 36.8 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting scikit-learn==0.22.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 33.4 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting scipy==1.4.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 21 kB/s s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting sentencepiece==0.1.85\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 34.6 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting six==1.13.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading six-1.13.0-py2.py3-none-any.whl (10 kB)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: torch==1.4.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (1.4.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting tqdm==4.41.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting transformers==2.3.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "\u001b[K     |████████████████████████████████| 447 kB 49.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting urllib3==1.25.7\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading urllib3-1.25.7-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting pytest==5.3.2\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
      "\u001b[K     |████████████████████████████████| 234 kB 49.4 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (20.3)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (0.1.9)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (1.6.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting py>=1.5.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading py-1.8.1-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hCollecting pluggy<1.0,>=0.12\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting attrs>=17.4.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Collecting more-itertools>=4.0.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Downloading more_itertools-8.2.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->pytest==5.3.2->-r requirements.txt (line 26)) (2.4.6)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==5.3.2->-r requirements.txt (line 26)) (3.1.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Building wheels for collected packages: nltk, sacremoses, opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449908 sha256=b375dc4c6bc358166912062fa1e5dc5e729794ab52cfb0ba67aa80c0fec1742b\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/e3/c9/b0/ed26a73ef75a53145820825afa8e2d2c9b30fe9f6c10cd3202\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.38-py3-none-any.whl size=884629 sha256=363649782bb9b2b98dead1018944248c368e5071541d38b352688a1e253a57d4\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/03/e9/be/8b52f6e7e8c333b56f9440575b4c5eb4d96d27b5d22df5a71e\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Building wheel for opennre (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25h  Created wheel for opennre: filename=opennre-0.1-py3-none-any.whl size=35176 sha256=627315b646ce2d5271758e4b6e7de2101651639e8a1651dababc4554af4a01f9\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-p50sl_tv/wheels/80/d6/aa/d506e992e917597a16c74838842636f7014d11260be4a6ddb0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Successfully built nltk sacremoses opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[31mERROR: awscli 1.18.34 has requirement botocore==1.15.34, but you'll have botocore 1.13.46 which is incompatible.\u001b[0m\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[31mERROR: awscli 1.18.34 has requirement s3transfer<0.4.0,>=0.3.0, but you'll have s3transfer 0.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Installing collected packages: six, nltk, urllib3, jmespath, botocore, s3transfer, boto3, Click, numpy, regex, tqdm, sacremoses, scipy, scikit-learn, sentencepiece, transformers, py, pluggy, attrs, more-itertools, pytest, opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: six\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: six 1.14.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling six-1.14.0:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled six-1.14.0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: urllib3\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: urllib3 1.25.8\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling urllib3-1.25.8:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled urllib3-1.25.8\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: jmespath\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: jmespath 0.9.5\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling jmespath-0.9.5:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled jmespath-0.9.5\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: botocore\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: botocore 1.15.34\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling botocore-1.15.34:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled botocore-1.15.34\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: s3transfer\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: s3transfer 0.3.3\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling s3transfer-0.3.3:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled s3transfer-0.3.3\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: boto3\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: boto3 1.12.34\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling boto3-1.12.34:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled boto3-1.12.34\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: Click\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: click 7.1.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling click-7.1.1:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled click-7.1.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: numpy\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: numpy 1.16.4\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling numpy-1.16.4:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled numpy-1.16.4\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: tqdm\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: tqdm 4.42.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling tqdm-4.42.1:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled tqdm-4.42.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: scipy\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: scipy 1.2.2\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling scipy-1.2.2:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled scipy-1.2.2\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: scikit-learn 0.21.2\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Uninstalling scikit-learn-0.21.2:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.21.2\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: opennre 0.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Can't uninstall 'opennre'. No files were found to uninstall.\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Successfully installed Click-7.0 attrs-19.3.0 boto3-1.10.46 botocore-1.13.46 jmespath-0.9.4 more-itertools-8.2.0 nltk-3.4.5 numpy-1.18.0 opennre-0.1 pluggy-0.13.1 py-1.8.1 pytest-5.3.2 regex-2019.12.20 s3transfer-0.2.1 sacremoses-0.0.38 scikit-learn-0.22.1 scipy-1.4.1 sentencepiece-0.1.85 six-1.13.0 tqdm-4.41.1 transformers-2.3.0 urllib3-1.25.7\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:22:31,117 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m /opt/conda/bin/python -m pip install . -r requirements.txt\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: wheel in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.34.2)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: nltk==3.4.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (3.4.5)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: boto3==1.10.46 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.10.46)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: botocore==1.13.46 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.13.46)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: certifi==2019.11.28 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (2019.11.28)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: chardet==3.0.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (3.0.4)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: Click==7.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (7.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: docutils==0.15.2 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (0.15.2)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: idna==2.8 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2.8)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: jmespath==0.9.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (0.9.4)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: joblib==0.14.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.14.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: numpy==1.18.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.18.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: python-dateutil==2.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (2.8.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: regex==2019.12.20 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (2019.12.20)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (2.22.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: s3transfer==0.2.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (0.2.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: sacremoses==0.0.38 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (0.0.38)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: scikit-learn==0.22.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (0.22.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (1.4.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: sentencepiece==0.1.85 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (0.1.85)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: six==1.13.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (1.13.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: torch==1.4.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (1.4.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: tqdm==4.41.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 23)) (4.41.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: transformers==2.3.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (2.3.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: urllib3==1.25.7 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (1.25.7)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: pytest==5.3.2 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (5.3.2)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (20.3)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (1.6.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (0.1.9)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (1.8.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (0.13.1)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (19.3.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest==5.3.2->-r requirements.txt (line 26)) (8.2.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->pytest==5.3.2->-r requirements.txt (line 26)) (2.4.6)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==5.3.2->-r requirements.txt (line 26)) (3.1.0)\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Building wheels for collected packages: opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Building wheel for opennre (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \u001b[?25h  Created wheel for opennre: filename=opennre-0.1-py3-none-any.whl size=35176 sha256=2dda1121735ff054fdf6b89401a06e1bacaa4fa84a39b4498ba87bf4ccb41e05\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-zoukvyyz/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Successfully built opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Installing collected packages: opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m   Attempting uninstall: opennre\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Found existing installation: opennre 0.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     Can't uninstall 'opennre'. No files were found to uninstall.\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Successfully installed opennre-0.1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:22:33,667 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"pretrain\": \"/opt/ml/input/data/pretrain\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"current_host\": \"algo-1-9lkag\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"algo-1-9lkag\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"pretrain\": {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"job_name\": \"pytorch-training-2020-04-17-03-21-41-792\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"master_hostname\": \"algo-1-9lkag\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-579019700964/pytorch-training-2020-04-17-03-21-41-792/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"module_name\": \"example/train_finre_cnn_softmax\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m             \"algo-1-9lkag\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         ],\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m         \"current_host\": \"algo-1-9lkag\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m     \"user_entry_point\": \"example/train_finre_cnn_softmax.py\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_HOSTS=[\"algo-1-9lkag\"]\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_USER_ENTRY_POINT=example/train_finre_cnn_softmax.py\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-9lkag\",\"hosts\":[\"algo-1-9lkag\"]}\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"pretrain\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_CHANNELS=[\"pretrain\",\"training\"]\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_CURRENT_HOST=algo-1-9lkag\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_MODULE_NAME=example/train_finre_cnn_softmax\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-579019700964/pytorch-training-2020-04-17-03-21-41-792/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"pretrain\":\"/opt/ml/input/data/pretrain\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-9lkag\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-9lkag\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pretrain\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-04-17-03-21-41-792\",\"log_level\":20,\"master_hostname\":\"algo-1-9lkag\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-579019700964/pytorch-training-2020-04-17-03-21-41-792/source/sourcedir.tar.gz\",\"module_name\":\"example/train_finre_cnn_softmax\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-9lkag\",\"hosts\":[\"algo-1-9lkag\"]},\"user_entry_point\":\"example/train_finre_cnn_softmax.py\"}\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m SM_CHANNEL_PRETRAIN=/opt/ml/input/data/pretrain\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m /opt/conda/bin/python -m example/train_finre_cnn_softmax\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m \n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m 2020-04-17 03:22:33,711 sagemaker-containers ERROR    ExecuteUserScriptError:\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m Command \"/opt/conda/bin/python -m example/train_finre_cnn_softmax\"\n",
      "\u001b[36malgo-1-9lkag_1  |\u001b[0m /opt/conda/bin/python: No module named example/train_finre_cnn_softmax\n",
      "\u001b[36mtmpzugroy_algo-1-9lkag_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmpzUgROY/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4226c388e263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                             train_instance_type=instance_type)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcifar10_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     def process(\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/local/local_session.pyc\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/local/entities.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/sagemaker/local/image.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpzUgROY/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/whn09/OpenNRE.git', 'branch': 'master'}\n",
    "\n",
    "cifar10_estimator = PyTorch(entry_point='example/train_finre_cnn_softmax.py',  # TODO bug\n",
    "                            source_dir='.',\n",
    "                            #git_config=git_config,\n",
    "                            role=role,\n",
    "                            framework_version='1.4.0',\n",
    "                            train_instance_count=1,\n",
    "                            train_instance_type=instance_type)\n",
    "\n",
    "cifar10_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint (in this case locally) which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "cifar10_predictor = cifar10_estimator.deploy(initial_instance_count=1,\n",
    "                                             instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%4s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = cifar10_predictor.predict(images.numpy())\n",
    "\n",
    "_, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%4s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_estimator.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
